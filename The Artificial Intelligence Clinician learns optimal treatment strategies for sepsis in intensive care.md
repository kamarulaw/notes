## The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care

##### **M. Komorowski et al.**

Summary: Sepsis is the third leading cause of death worldwide and the main cause of mortality in hospitals, but the best treatment strategy remains uncertain.  In particular, evidence suggests that current practices in the administration of intravenous fluids and vasopressors are suboptimal and likely induce harm in a proportion of patients.  

### Notes 
- Sepsis is defined as severe infection leading to life-threatening acute organ dysfunction.  The management of intravenous fluids and vasopressors in sepsis is a key clinical challenge and a top research priority
- “AI Clinician” was built and validated on two large non-overlapping ICU databases containing data routinely collected from adult patients in the US
- A MDP was used to model the patient environment and trajectories
- Evaluating the performance of this new AI policy using the trajectories of patients generated by another policy (the clinicians’ policy) is termed off-policy evaluation.  It was crucial to obtain reliable estimates of the performance of this new policy without deploying it, as executing a bad policy would be dangerous for patients
- On average, the AI Clinician recommended lower doses of intravenous fluids and higher doses of vasopressors than the clinicians’ actual treatments
- When clinicians’ actual treatments varied from the AI Clinician’s suggested policy, this was most commonly administration of too little vasopressor

### Methods

#### Building the Computational Model
- The true patient physiological state is only partially represented by the data available, and therefore the disease process could be formulated as a partially observable MDP.  A MDP was used to approximate patient trajectory and to model the 
- MDP is defined by the tuple (S, A, T, R, gamma)
  - S: finite set of states (in their model, the health states of patients)
  - A: finite set of actions available from state s (in their model, the dose prescribed of intravenous fluids and vasopressors converted into discrete decisions)
  - T: the transition matrix, containing the probability that action a in state s at time t will lead to state s’ at time t + 1, which describes the dynamics of the system 
  - R: The immediate reward received for transitioning into state s’.  Transitions to desirable states yield a positive reward, and reaching undesirable states generates a penalty
  - gamma: the discount factor, which allows modeling of the fact that a future reward is worth less than an immediate reward
- Management of ICU patients with sepsis is extremely complex and includes several principles such as rapid control of the source of infection, correction of hypovolemia, and management of secondary organ failures
- Including all these potential interventions as actions in the MDP would have required a much larger dataset.  The key challenge is arguably the management of intravenous fluids and vasopressors
- Consequently, the authors focused on medical decisions regarding total volume of intravenous fluids and maximum dose of vasopressors administered over each 4-h period
- Intravenous fluids included boluses and background infusions of crystalloids, colloids, and blood products, normalized by tonicity 
- The vasopressors included norepinephrine, epinephrine, vasopressin, dopamine, and phenylephrine and were converted when necessary to norepinephrine-equivalent using previously published dose correspondence
- To define the action space, the dose of each treatment was represented as one of five possible choices.  Choice 1 being “no drug given” and the remaining non-null doses divided into four quartiles 
- The combination of the two treatments produced 25 possible discrete actions.  They expressed the suggested dose as the median of each dose bin matching a suggested action
- Sequences of successive states and actions are referred to as patients’ trajectories.  Models used either hospital mortality or 90-d mortality as the sole defining factor for the system-defined penalty and reward
  - When a patient survived, a positive reward was released at the end of each patient’s trajectory (a reward of +100)
  - A negative reward (a ‘penalty’ of -100) was issued if the patient died
- Estimated the transition matrix by counting how many times each transition was observed in the MIMIC-III training dataset and converting the transition counts to a stochastic matrix
- In high-risk environments (where executing a bad policy could cause harm) limiting the action space to known options is a sensible choice to increase the safety of the model.  Authors restricted the set of actions to choose from to frequently observed actions taken by clinicians and excluded transitions even fewer than five times.  As such, the resulting AI policy suggests the best possible treatment among all the options chosen by clinicians 
