### Machine Learning Glossary 

- **Concordance Index**: Quantifies the quality of rankings, is the standard performance measure for model assessment in SA.  In contrast, the standard approach to learning the popular proportional hazard model is based on Cox’s partial likelihood
- **Discriminative model**: a model of the conditional probability of the target, given an observation x
- **Generative model**: a statistical model of the joint probability distribution
  - [Types of Generative-AI Models](https://www.eweek.com/artificial-intelligence/generative-ai-model/)
- **Gibbs Sampling**: An algorithm for obtaining a sequence of observations which are approximated from a specified multivariate probability distribution, when direct sampling is difficult.  Commonly used as a means of statistical inference, especially Bayesian inference.  It is a randomized algorithm and is an alternative to deterministic algorithms for statistical inference such as the EM algorithm
- **Kalman Filter**: An algorithm that uses a series of measurements observed over time, containing statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more accurate than those based on a single measurement alone, by estimating a joint prob distribution over the variables for each timeframe
- **Latent Dirichlet Allocation (LDA)**: a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar
- **Ornstein-Uhlenbeck cone function**: Is a stochastic process that, roughly speaking, describes the velocity of a massive Brownian particle under the influence of friction 
- **Topic model**: a type of statistical model for discovering the abstract “topics” that occur in a collection of documents
- **Unsupervised learning**: a branch of machine learning that learns from test data that has not been labeled, classified, or categorizes.  Instead of responding to feedback USL identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data
